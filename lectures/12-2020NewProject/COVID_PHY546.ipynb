{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COVID-PHY546.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik8HaOZEEyPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQQxrhweEzA1",
        "colab_type": "text"
      },
      "source": [
        "# Modelling COVID epidemic and learning how to access to data\n",
        "This Notebook will be used to evaluate a number of learned python utilities and some new ones. We will be working with real data, and the goel of this is to make a useful and timely tool."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxT1wdP1F7Pq",
        "colab_type": "text"
      },
      "source": [
        "# Downloading multiple Files\n",
        "\n",
        "We will be obtaining our data from the world head organization Situation Reports: https://www.who.int/emergencies/diseases/novel-coronavirus-2019/situation-reports/. These reports are updated daily. So we want to write a code that is up to date at any time we run it. For this we will need a procedure to download multiple pdf files from a web site.\n",
        "\n",
        "To do this we are going to make use of several libraries:\n",
        "* from bs4 import BeautifulSoup\n",
        " Beautiful Soup is a Python library for pulling data out of HTML and XML files. It works with your favorite parser to provide idiomatic ways of navigating, searching, and modifying the parse tree. It commonly saves programmers hours or days of work.\n",
        " See more in https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
        "* import re\n",
        "Regular expressions (called REs, or regexes, or regex patterns) are essentially a tiny, highly specialized programming language embedded inside Python and made available through the re module. Using this little language, you specify the rules for the set of possible strings that you want to match; this set might contain English sentences, or e-mail addresses, or TeX commands, or anything you like. You can then ask questions such as “Does this string match the pattern?”, or “Is there a match for the pattern anywhere in this string?”. You can also use REs to modify a string or to split it apart in various ways.\n",
        "See more in https://docs.python.org/3/howto/regex.html\n",
        "* import os\n",
        "The OS module in python provides functions for interacting with the operating system. OS, comes under Python’s standard utility modules. This module provides a portable way of using operating system dependent functionality. \n",
        "See more in https://www.geeksforgeeks.org/os-module-python-examples/\n",
        "\n",
        "* import urllib\n",
        "Urllib module is the URL handling module for python. It is used to fetch URLs (Uniform Resource Locators). It uses the urlopen function and is able to fetch URLs using a variety of different protocols.\n",
        "See more in\n",
        "https://www.geeksforgeeks.org/python-urllib-module/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3TVh7VNEmYg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from urllib import request\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import os\n",
        "import urllib\n",
        "\n",
        "# Lets make the directory to store the data\n",
        "# We use the os library for this\n",
        "def make1dir(dirname):\n",
        "  '''parameter: dirname  Name of directory to be created\n",
        "  '''\n",
        "  try:\n",
        "    # Create target Directory\n",
        "     os.mkdir(dirname)\n",
        "     print(\"Directory \" , dirname ,  \" Created \") \n",
        "  except FileExistsError:\n",
        "     print(\"Directory \" , dirname ,  \" already exists\")\n",
        "\n",
        "newdir = 'PHY546'\n",
        "make1dir(newdir)\n",
        "# we need a nested directory \n",
        "newdir = 'PHY546/COVID19'\n",
        "make1dir(newdir)\n",
        "\n",
        "# Now we use beautiful shop, re and urllib\n",
        "# \n",
        "\n",
        "url = \"https://www.who.int/emergencies/diseases/novel-coronavirus-2019/situation-reports/\"\n",
        "\n",
        "# open the url\n",
        "response = request.urlopen(url).read()\n",
        "# soup is now a beautifulsoup object object, which represents the document as a nested data structure: \n",
        "soup= BeautifulSoup(response, \"html.parser\")   \n",
        "# We are now going to find all the links to a pdf page within the page\n",
        "# we use .find_all and we use re.compile to find all the files that\n",
        "# contain the regular expression .pdf  \n",
        "links = soup.find_all('a', href=re.compile(r'(.pdf)'))\n",
        "\n",
        "# clean the pdf link names\n",
        "url_list = []\n",
        "for el in links:\n",
        "    print(el['href'])\n",
        "    if(el['href'].startswith('http')):\n",
        "        url_list.append(el['href'])\n",
        "    else:\n",
        "        url_list.append(\"https://www.who.int\" + el['href'])\n",
        "\n",
        "print(url_list)\n",
        "\n",
        "# download the pdfs to a specified location\n",
        "# In this case newdir\n",
        "for url in url_list:\n",
        "    #print(url)\n",
        "    #mydir = '/Users/marivi/Desktop/tmp/COVID19/'\n",
        "    mydir = newdir\n",
        "    fullfilename = os.path.join(mydir, url.replace(\"https://www.who.int/docs/default-source/coronaviruse/situation-reports/\", \"\"))\n",
        "    fullfilename = fullfilename[:fullfilename.find(\"pdf\")]+'pdf'\n",
        "    request.urlretrieve(url, fullfilename)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U10D1g_xFtnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can see all the files downloaded (there might be others)\n",
        "for root, dirs, files in os.walk(\".\"):\n",
        "    for filename in files:\n",
        "        print(filename)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fD9q9mq6JQmo",
        "colab_type": "text"
      },
      "source": [
        "# Extracting data from PDF files, in particular from tables\n",
        "\n",
        "Now that we have downloaded the files we should read the tables. To do this we will use a library called tabula-py.\n",
        "Tabula-py is a simple Python wrapper of tabula-java, which can read the table of PDF. You can read tables from PDF and convert into pandas’ DataFrame. tabula-py also enables you to convert a PDF file into CSV/TSV/JSON file. A lot of what we will use is in here https://tabula-py.readthedocs.io/en/latest/\n",
        "\n",
        "## Check Java environment and install tabula-py\n",
        "tabula-py requires java environment so let's check the java environment on your machine.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0H-Q0udSoqE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "13123c5b-2cfe-4d67-eeea-49914faddde5"
      },
      "source": [
        "!java -version\n",
        "# To be more precisely, it's better to use `{sys.executable} -m pip install tabula-py`\n",
        "!pip install -q tabula-py\n",
        "import tabula\n",
        "import pandas as pd\n",
        "\n",
        "tabula.environment_info()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"11.0.6\" 2020-01-14\n",
            "OpenJDK Runtime Environment (build 11.0.6+10-post-Ubuntu-1ubuntu118.04.1)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.6+10-post-Ubuntu-1ubuntu118.04.1, mixed mode, sharing)\n",
            "Python version:\n",
            "    3.6.9 (default, Nov  7 2019, 10:44:02) \n",
            "[GCC 8.3.0]\n",
            "Java version:\n",
            "    openjdk version \"11.0.6\" 2020-01-14\n",
            "OpenJDK Runtime Environment (build 11.0.6+10-post-Ubuntu-1ubuntu118.04.1)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.6+10-post-Ubuntu-1ubuntu118.04.1, mixed mode, sharing)\n",
            "tabula-py version: 2.1.0\n",
            "platform: Linux-4.14.137+-x86_64-with-Ubuntu-18.04-bionic\n",
            "uname:\n",
            "    uname_result(system='Linux', node='b972a9ad1994', release='4.14.137+', version='#1 SMP Thu Aug 8 02:47:02 PDT 2019', machine='x86_64', processor='x86_64')\n",
            "linux_distribution: ('Ubuntu', '18.04', 'bionic')\n",
            "mac_ver: ('', ('', '', ''), '')\n",
            "    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCwZyvozKMyq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "933bdf42-7d2a-4260-c52b-c8d5c96eb4ad"
      },
      "source": [
        "# Lets look a one of the reports\n",
        "pdf_path1 = \"https://www.who.int/docs/default-source/coronaviruse/situation-reports/20200324-sitrep-64-covid-19.pdf\"\n",
        "data = tabula.read_pdf(pdf_path1, pages=\"3-7\",lattice=True, pandas_options={\"header\": [0, 1]}, stream=True)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Got stderr: Mar 27, 2020 7:32:56 PM org.apache.pdfbox.pdmodel.font.PDCIDFontType2 <init>\n",
            "INFO: OpenType Layout tables used in font BCDIEE+Calibri-Bold are not implemented in PDFBox and will be ignored\n",
            "Mar 27, 2020 7:32:58 PM org.apache.pdfbox.pdmodel.font.PDCIDFontType2 <init>\n",
            "INFO: OpenType Layout tables used in font BCDHEE+Calibri are not implemented in PDFBox and will be ignored\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv9c9VhnBHRl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "69f7a755-0fa0-4fd2-f14b-8dc1e9ab2a97"
      },
      "source": [
        "\n",
        "# Lets analyze the data, for example lets look for the row\n",
        "# that contained the data for a given country (Spain)\n",
        "#len(data)\n",
        "for item in data:\n",
        "  #print(len(item))\n",
        "  for ind in item.index:\n",
        "    for col in item.columns:\n",
        "      if item[col][ind]=='Spain':\n",
        "        newdf = (item.iloc[[ind]])\n",
        "\n",
        "print(newdf)  \n",
        "\n",
        "# We can write a function to search for the country we want:\n",
        "\n",
        "def find_country(name, data):\n",
        "    \"\"\" Utitily to analyze data obtained with tabula-py\n",
        "    Given a list of different dataframe types, returns a data frame containing\n",
        "    just a given row that mataches the search string 'name'\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    name: str  name of the string to find in the list\n",
        "    data: list of pd Dataframes, the return of reading tables from a pdf\n",
        "          obtained with tabula-py\n",
        "    Returns:\n",
        "    --------\n",
        "    list_idx, pd_idx: the location of the target dataframe in the list\n",
        "                        and the row index within this dataframe      \n",
        "\n",
        "     \"\"\"\n",
        "    for item in data:\n",
        "      for ind in item.index:\n",
        "        for col in item.columns:\n",
        "          if item[col][ind] == name:\n",
        "            list_idx = data.index(item)\n",
        "            pd_idx = ind\n",
        "      return(list_idx, pd_idx) \n",
        "\n",
        "name = 'Spain'\n",
        "x,y = find_country(name, data)\n",
        "print(x,y)\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       0      1     2     3    4   ...   9   10   11   12   13\n",
            "26  Spain  33089  4517  2182  462  ...  NaN NaN  NaN  NaN  NaN\n",
            "\n",
            "[1 rows x 14 columns]\n",
            "0 26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URGWinb3wtfJ",
        "colab_type": "text"
      },
      "source": [
        "# Resume so far\n",
        "\n",
        "We now have learned 2 separate things:\n",
        "* How to batch download all the files of a specific type from a given webpage\n",
        "* How to 'roughly' browse through all the data obtained from a list of tables\n",
        "which are returned by tabula-py reading a pdf file. This list of tables is a list of Pandas dataframes. We wrote a function  to locate the position of a target string within the list and within the dataframe\n",
        "\n",
        "# What we need to do next\n",
        "\n",
        "* Check that all the files we download maintain the same structure\n",
        "* locate the date from each pdf file\n",
        "* create a new dataframe with the data for a specific country ordered by date.\n",
        "* plot the data for a single country\n",
        "* plot the data for several countries\n",
        "* Analyze data?\n",
        "* Other suggestions?\n",
        "\n"
      ]
    }
  ]
}